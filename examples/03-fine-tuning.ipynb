{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning a Pretrained Network for Style Recognition\n",
    "\n",
    "这个讲了从 caffe 的 model zoo 拿到别人训练好了的 model，如何把它 tune 得更适合自己的情况。\n",
    "\n",
    "In this example, we'll explore a common approach that is particularly useful in real-world applications: take a pre-trained Caffe network and fine-tune the parameters on your custom data.\n",
    "\n",
    "The upside of such approach is that, since pre-trained networks are learned on a large set of images, the intermediate layers capture the \"semantics\" of the general visual appearance. Think of it as a very powerful feature that you can treat as a black box. On top of that, only a few layers will be needed to obtain a very good performance of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will need to prepare the data. This involves the following parts:\n",
    "(1) Get the ImageNet ilsvrc pretrained model with the provided shell scripts.\n",
    "(2) Download a subset of the overall Flickr style dataset for this demo.\n",
    "(3) Compile the downloaded Flickr dataset into a database that Caffe can then consume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tzx/dev/caffe-rc3\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "print os.path.realpath(os.getcwd())\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './python')\n",
    "\n",
    "import caffe\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This downloads the ilsvrc auxiliary data (mean file, etc),\n",
    "# and a subset of 2000 images for the style recognition task.\n",
    "\n",
    "\n",
    "\n",
    "#!data/ilsvrc12/get_ilsvrc_aux.sh\n",
    "# 还是用我们已经下载好了的数据。cp 过来就好。\n",
    "!data/ilsvrc12/get_ilsvrc_aux_cvrs.sh \n",
    "print \"done get files.\\n\"\n",
    "\n",
    "# 提前解压这个文件，用【迅雷】把图片下载了直接拷贝过去。\n",
    "# examples/finetune_flickr_style/flickr_style.csv.gz\n",
    "\n",
    "# 如果图片已经存在，这个脚本不会再下载（还得通过sha1 校验）。\n",
    "!scripts/download_model_binary.py models/bvlc_reference_caffenet\n",
    "print \"done get model binary.\\n\"\n",
    "\n",
    "!python examples/finetune_flickr_style/assemble_data.py \\\n",
    "    --workers=-1 --images=2000 --seed=1701 --label=5\n",
    "print \"done assemble.\\n\"\n",
    "    \n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show what is the difference between the fine-tuning network and the original caffe model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!diff models/bvlc_reference_caffenet/train_val.prototxt models/finetune_flickr_style/train_val.prototxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your record, if you want to train the network in pure C++ tools, here is the command:\n",
    "\n",
    "<code>\n",
    "build/tools/caffe train \\\n",
    "    -solver models/finetune_flickr_style/solver.prototxt \\\n",
    "    -weights models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel \\\n",
    "    -gpu 0\n",
    "</code>\n",
    "\n",
    "However, we will train using Python in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "niter = 200\n",
    "# losses will also be stored in the log\n",
    "train_loss = np.zeros(niter)\n",
    "scratch_train_loss = np.zeros(niter)\n",
    "\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "# We create a solver that fine-tunes from a previously trained network.\n",
    "solver = caffe.SGDSolver('models/finetune_flickr_style/solver.prototxt')\n",
    "solver.net.copy_from('models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel')\n",
    "# For reference, we also create a solver that does no finetuning.\n",
    "scratch_solver = caffe.SGDSolver('models/finetune_flickr_style/solver.prototxt')\n",
    "\n",
    "# We run the solver for niter times, and record the training loss.\n",
    "for it in range(niter):\n",
    "    solver.step(1)  # SGD by Caffe\n",
    "    scratch_solver.step(1)\n",
    "    # store the train loss\n",
    "    train_loss[it] = solver.net.blobs['loss'].data\n",
    "    scratch_train_loss[it] = scratch_solver.net.blobs['loss'].data\n",
    "    if it % 10 == 0:\n",
    "        print 'iter %d, finetune_loss=%f, scratch_loss=%f' % (it, train_loss[it], scratch_train_loss[it])\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the training loss produced by the two training procedures respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(np.vstack([train_loss, scratch_train_loss]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the fine-tuning procedure produces a more smooth loss function change, and ends up at a better loss. A closer look at small values, clipping to avoid showing too large loss during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(np.vstack([train_loss, scratch_train_loss]).clip(0, 4).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the testing accuracy after running 200 iterations. Note that we are running a classification task of 5 classes, thus a chance accuracy is 20%. As we will reasonably expect, the finetuning result will be much better than the one from training from scratch. Let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_iters = 10\n",
    "accuracy = 0\n",
    "scratch_accuracy = 0\n",
    "for it in arange(test_iters):\n",
    "    solver.test_nets[0].forward()\n",
    "    accuracy += solver.test_nets[0].blobs['accuracy'].data\n",
    "    scratch_solver.test_nets[0].forward()\n",
    "    scratch_accuracy += scratch_solver.test_nets[0].blobs['accuracy'].data\n",
    "accuracy /= test_iters\n",
    "scratch_accuracy /= test_iters\n",
    "print 'Accuracy for fine-tuning:', accuracy\n",
    "print 'Accuracy for training from scratch:', scratch_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huzzah! So we did finetuning and it is awesome. Let's take a look at what kind of results we are able to get with a longer, more complete run of the style recognition dataset. Note: the below URL might be occassionally down because it is run on a research machine.\n",
    "\n",
    "http://demo.vislab.berkeleyvision.org/"
   ]
  }
 ],
 "metadata": {
  "description": "Fine-tune the ImageNet-trained CaffeNet on new data.",
  "example_name": "Fine-tuning for Style Recognition",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "priority": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
